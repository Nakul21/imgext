const CHUNK_SIZE = 512; // Size to split large images into
const MAX_BATCH_SIZE = 16; // Maximum number of tensors to process at once

async function preprocessImageForDetection(imageElement) {
    // Calculate number of chunks needed
    const numChunksX = Math.ceil(imageElement.width / CHUNK_SIZE);
    const numChunksY = Math.ceil(imageElement.height / CHUNK_SIZE);
    
    const results = [];
    
    for (let y = 0; y < numChunksY; y++) {
        for (let x = 0; x < numChunksX; x++) {
            const chunkCanvas = document.createElement('canvas');
            chunkCanvas.width = Math.min(CHUNK_SIZE, imageElement.width - x * CHUNK_SIZE);
            chunkCanvas.height = Math.min(CHUNK_SIZE, imageElement.height - y * CHUNK_SIZE);
            
            const ctx = chunkCanvas.getContext('2d');
            ctx.drawImage(imageElement,
                x * CHUNK_SIZE, y * CHUNK_SIZE, // Source position
                chunkCanvas.width, chunkCanvas.height, // Source dimensions
                0, 0, // Destination position
                chunkCanvas.width, chunkCanvas.height // Destination dimensions
            );
            
            const tensor = tf.tidy(() => {
                const t = tf.browser.fromPixels(chunkCanvas)
                    .resizeNearestNeighbor(TARGET_SIZE)
                    .toFloat();
                const mean = tf.scalar(255 * DET_MEAN);
                const std = tf.scalar(255 * DET_STD);
                return t.sub(mean).div(std).expandDims();
            });
            
            results.push({
                tensor,
                x: x * CHUNK_SIZE,
                y: y * CHUNK_SIZE
            });
            
            // Force garbage collection after each chunk
            await tf.nextFrame();
        }
    }
    
    return results;
}

async function detectAndRecognizeText(imageElement) {
    const deviceCaps = getDeviceCapabilities();
    extractedData = []; // Reset extracted data
    
    try {
        // Process image in chunks
        const chunks = await preprocessImageForDetection(imageElement);
        
        for (let i = 0; i < chunks.length; i++) {
            const chunk = chunks[i];
            
            // Process each chunk
            let prediction = null;
            try {
                prediction = await detectionModel.execute(chunk.tensor);
                prediction = tf.squeeze(prediction, 0);
                
                const heatmapCanvas = document.createElement('canvas');
                heatmapCanvas.width = CHUNK_SIZE;
                heatmapCanvas.height = CHUNK_SIZE;
                await tf.browser.toPixels(prediction, heatmapCanvas);
                
                // Extract bounding boxes for this chunk
                const boxes = extractBoundingBoxesFromHeatmap(heatmapCanvas, [CHUNK_SIZE, CHUNK_SIZE]);
                
                // Adjust bounding box coordinates based on chunk position
                boxes.forEach(box => {
                    box.coordinates = box.coordinates.map(coord => [
                        (coord[0] * CHUNK_SIZE + chunk.x) / imageElement.width,
                        (coord[1] * CHUNK_SIZE + chunk.y) / imageElement.height
                    ]);
                });
                
                // Process text recognition in batches
                const crops = generateCrops(imageElement, boxes);
                for (let j = 0; j < crops.length; j += MAX_BATCH_SIZE) {
                    const batchCrops = crops.slice(j, j + MAX_BATCH_SIZE);
                    await processBatch(batchCrops, extractedData);
                    await tf.nextFrame(); // Allow GC between batches
                }
                
            } finally {
                // Cleanup tensors
                if (prediction) prediction.dispose();
                chunk.tensor.dispose();
            }
            
            // Force garbage collection after each chunk
            await tf.nextFrame();
            tf.engine().startScope();
            tf.engine().endScope();
        }
        
        return extractedData;
        
    } catch(error) {
        console.error('Error in detectAndRecognizeText:', error);
        throw error;
    } finally {
        // Final cleanup
        tf.engine().startScope();
        tf.engine().endScope();
        await tf.nextFrame();
    }
}

async function processBatch(batch, extractedData) {
    let inputTensor = null;
    let predictions = null;
    let probabilities = null;
    
    try {
        inputTensor = preprocessImageForRecognition(batch.map(crop => crop.canvas));
        predictions = await recognitionModel.executeAsync(inputTensor);
        probabilities = tf.softmax(predictions, -1);
        
        // Process predictions immediately and dispose
        const words = await processRecognitionResults(probabilities);
        
        words.forEach((word, index) => {
            if (word && batch[index]) {
                extractedData.push({
                    word: word,
                    boundingBox: batch[index].bbox
                });
            }
        });
        
    } finally {
        // Cleanup tensors
        if (inputTensor) inputTensor.dispose();
        if (predictions) predictions.dispose();
        if (probabilities) probabilities.dispose();
    }
    
    // Force garbage collection
    await tf.nextFrame();
}

async function processRecognitionResults(probabilities) {
    const bestPath = tf.unstack(tf.argMax(probabilities, -1), 0);
    const words = decodeText(bestPath).split(' ');
    
    // Cleanup bestPath tensors
    bestPath.forEach(t => t.dispose());
    
    return words;
}

async function handleCapture() {
    disableCaptureButton();
    showLoading('Processing image...');
    
    try {
        await ensureModelsLoaded();
        
        // Clear previous results
        tf.engine().startScope();
        
        // Capture and resize image
        const captureCanvas = document.createElement('canvas');
        captureCanvas.width = CHUNK_SIZE;
        captureCanvas.height = CHUNK_SIZE;
        captureCanvas.getContext('2d').drawImage(video, 0, 0, CHUNK_SIZE, CHUNK_SIZE);
        
        imageDataUrl = captureCanvas.toDataURL('image/jpeg', 0.8);
        
        const img = new Image();
        await new Promise((resolve, reject) => {
            img.onload = resolve;
            img.onerror = reject;
            img.src = imageDataUrl;
        });
        
        extractedData = await detectAndRecognizeText(img);
        extractedText = extractedData.map(item => item.word).join(' ');
        
        // Update UI
        resultElement.textContent = `Extracted Text: ${extractedText}`;
        previewCanvas.style.display = 'block';
        previewCanvas.getContext('2d').drawImage(img, 0, 0, previewCanvas.width, previewCanvas.height);
        
        confirmButton.style.display = 'inline-block';
        retryButton.style.display = 'inline-block';
        captureButton.style.display = 'none';
        
    } catch (error) {
        console.error('Error during capture:', error);
        resultElement.textContent = 'Error occurred during processing';
    } finally {
        tf.engine().endScope();
        enableCaptureButton();
        hideLoading();
        
        // Final cleanup
        await tf.nextFrame();
        tf.disposeVariables();
    }
}

function monitorMemoryUsage() {
    setInterval(() => {
        const info = tf.memory();
        console.log('Memory usage:', {
            numTensors: info.numTensors,
            numBytesInGPU: info.numBytesInGPU,
            numBytes: info.numBytes,
            numDataBuffers: info.numDataBuffers,
            unreliable: info.unreliable,
            reasons: info.reasons
        });
        
        if (info.numTensors > 200 || info.numBytesInGPU > 500000000) {
            console.warn('High memory usage detected - forcing cleanup');
            tf.engine().startScope();
            tf.engine().endScope();
            tf.disposeVariables();
        }
    }, 1000);
}
