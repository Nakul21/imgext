async function getHeatMapFromImage(imageObject) {
    let tensor = null;
    let prediction = null;
    try {
        // Wrap the tensor creation in tidy
        tensor = tf.tidy(() => {
            return preprocessImageForDetection(imageObject);
        });
        
        // Execute model outside tidy since it's async
        prediction = await detectionModel.execute(tensor);
        prediction = tf.squeeze(prediction, 0);
        if (Array.isArray(prediction)) {
            prediction = prediction[0];
        }
        
        const heatmapCanvas = document.createElement('canvas');
        heatmapCanvas.width = imageObject.width;
        heatmapCanvas.height = imageObject.height;
        await tf.browser.toPixels(prediction, heatmapCanvas);
        
        return heatmapCanvas;
    } finally {
        // Clean up tensors
        if (tensor) tensor.dispose();
        if (prediction) prediction.dispose();
    }
}

function preprocessImageForDetection(imageElement) {
    return tf.tidy(() => {
        const tensor = tf.browser
            .fromPixels(imageElement)
            .resizeNearestNeighbor(TARGET_SIZE)
            .toFloat();
            
        const mean = tf.scalar(255 * DET_MEAN);
        const std = tf.scalar(255 * DET_STD);
        return tensor.sub(mean).div(std).expandDims();
    });
}

function preprocessImageForRecognition(crops) {
    return tf.tidy(() => {
        const targetSize = [32, 128];
        const tensors = crops.map((crop) => {
            let h = crop.height;
            let w = crop.width;
            let resizeTarget, paddingTarget;
            let aspectRatio = targetSize[1] / targetSize[0];
            
            if (aspectRatio * h > w) {
                resizeTarget = [targetSize[0], Math.round((targetSize[0] * w) / h)];
                paddingTarget = [
                    [0, 0],
                    [0, targetSize[1] - Math.round((targetSize[0] * w) / h)],
                    [0, 0],
                ];
            } else {
                resizeTarget = [Math.round((targetSize[1] * h) / w), targetSize[1]];
                paddingTarget = [
                    [0, targetSize[0] - Math.round((targetSize[1] * h) / w)],
                    [0, 0],
                    [0, 0],
                ];
            }
            
            return tf.browser
                .fromPixels(crop)
                .resizeNearestNeighbor(resizeTarget)
                .pad(paddingTarget, 0)
                .toFloat()
                .expandDims();
        });
        
        const tensor = tf.concat(tensors);
        const mean = tf.scalar(255 * REC_MEAN);
        const std = tf.scalar(255 * REC_STD);
        return tensor.sub(mean).div(std);
    });
}

async function processBatch(batch, extractedData) {
    let inputTensor = null;
    let predictions = null;
    let probabilities = null;
    let bestPath = null;
    
    try {
        // Create input tensor
        inputTensor = preprocessImageForRecognition(batch.map(crop => crop.canvas));
        
        // Run model
        predictions = await recognitionModel.executeAsync(inputTensor);
        
        // Process results
        probabilities = tf.softmax(predictions, -1);
        bestPath = tf.unstack(tf.argMax(probabilities, -1), 0);
        
        const words = decodeText(bestPath);
        
        words.split(' ').forEach((word, index) => {
            if (word && batch[index]) {
                extractedData.push({
                    word: word,
                    boundingBox: batch[index].bbox
                });
            }
        });
    } finally {
        // Clean up tensors
        if (inputTensor) inputTensor.dispose();
        if (predictions) predictions.dispose();
        if (probabilities) probabilities.dispose();
        if (bestPath) bestPath.forEach(t => t.dispose());
    }
}

async function detectAndRecognizeText(imageElement) {
    if (isMobile()) {
        useCPU();
    }

    let heatmapCanvas = null;
    
    try {
        // Get heatmap
        heatmapCanvas = await getHeatMapFromImage(imageElement);
        const boundingBoxes = extractBoundingBoxesFromHeatmap(heatmapCanvas, TARGET_SIZE);

        // Setup preview canvas
        previewCanvas.width = TARGET_SIZE[0];
        previewCanvas.height = TARGET_SIZE[1];
        const ctx = previewCanvas.getContext('2d');
        ctx.drawImage(imageElement, 0, 0);

        const crops = [];

        // Generate crops
        for (const box of boundingBoxes) {
            const [x1, y1] = box.coordinates[0];
            const [x2, y2] = box.coordinates[2];
            const width = (x2 - x1) * imageElement.width;
            const height = (y2 - y1) * imageElement.height;
            const x = x1 * imageElement.width;
            const y = y1 * imageElement.height;

            ctx.strokeStyle = box.config.stroke;
            ctx.lineWidth = 2;
            ctx.strokeRect(x, y, width, height);

            const croppedCanvas = document.createElement('canvas');
            croppedCanvas.width = Math.min(width, 128);
            croppedCanvas.height = Math.min(height, 32);
            croppedCanvas.getContext('2d').drawImage(
                imageElement, 
                x, y, width, height,
                0, 0, width, height
            );

            crops.push({
                canvas: croppedCanvas,
                bbox: {
                    x: Math.round(x),
                    y: Math.round(y),
                    width: Math.round(width),
                    height: Math.round(height)
                }
            });
        }

        // Process crops in smaller batches
        const batchSize = isMobile() ? 8 : 32;
        
        for (let i = 0; i < crops.length; i += batchSize) {
            const batch = crops.slice(i, i + batchSize);
            await processBatch(batch, extractedData);
            
            // Force garbage collection between batches
            await tf.nextFrame();
        }

        return extractedData;

    } catch(error) {
        console.error('Error in detectAndRecognizeText:', error);
        throw error;
    } finally {
        // Clean up any remaining tensors
        tf.engine().startScope();
        tf.engine().endScope();
        await tf.nextFrame();
    }
}
