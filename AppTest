// Constants for maximum dimensions
const MAX_TEXTURE_SIZE = 4096;

// Modified preprocessImageForDetection function
function preprocessImageForDetection(imageElement) {
    return tf.tidy(() => {
        // Calculate scale to fit within texture limits while maintaining aspect ratio
        const scale = Math.min(
            MAX_TEXTURE_SIZE / imageElement.width,
            MAX_TEXTURE_SIZE / imageElement.height,
            1
        );
        
        const scaledWidth = Math.floor(imageElement.width * scale);
        const scaledHeight = Math.floor(imageElement.height * scale);
        
        // Create a temporary canvas for resizing
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = scaledWidth;
        tempCanvas.height = scaledHeight;
        const ctx = tempCanvas.getContext('2d');
        ctx.drawImage(imageElement, 0, 0, scaledWidth, scaledHeight);
        
        // Convert to tensor with controlled dimensions
        let tensor = tf.browser.fromPixels(tempCanvas);
        
        // Resize to target size if different from current size
        if (scaledWidth !== TARGET_SIZE[0] || scaledHeight !== TARGET_SIZE[1]) {
            tensor = tensor.resizeNearestNeighbor(TARGET_SIZE);
        }
        
        tensor = tensor.toFloat();
        const mean = tf.scalar(255 * DET_MEAN);
        const std = tf.scalar(255 * DET_STD);
        return tensor.sub(mean).div(std).expandDims();
    });
}

// Modified handleCapture function
async function handleCapture() {
    disableCaptureButton();
    showLoading('Processing image...');

    await ensureModelsLoaded();

    // Get the video dimensions
    const videoWidth = video.videoWidth;
    const videoHeight = video.videoHeight;
    
    // Calculate scale to fit within texture limits
    const scale = Math.min(
        MAX_TEXTURE_SIZE / videoWidth,
        MAX_TEXTURE_SIZE / videoHeight,
        1
    );
    
    const scaledWidth = Math.floor(videoWidth * scale);
    const scaledHeight = Math.floor(videoHeight * scale);

    // Set canvas dimensions to scaled size
    canvas.width = scaledWidth;
    canvas.height = scaledHeight;
    canvas.getContext('2d').drawImage(video, 0, 0, scaledWidth, scaledHeight);

    imageDataUrl = canvas.toDataURL('image/jpeg', isMobile() ? 0.7 : 0.9);
    
    const img = new Image();
    img.src = imageDataUrl;
    img.onload = async () => {
        try {
            extractedData = await detectAndRecognizeText(img);
            extractedText = extractedData.map(item => item.word).join(' ');
            resultElement.textContent = `Extracted Text: ${extractedText}`;
            
            // Set preview canvas dimensions
            previewCanvas.width = scaledWidth;
            previewCanvas.height = scaledHeight;
            previewCanvas.getContext('2d').drawImage(img, 0, 0);
            
            previewCanvas.style.display = 'block';
            confirmButton.style.display = 'inline-block';
            retryButton.style.display = 'inline-block';
            captureButton.style.display = 'none';
        } catch (error) {
            console.error('Error during text extraction:', error);
            resultElement.textContent = 'Error occurred during text extraction';
        } finally {
            enableCaptureButton();
            hideLoading();
            tf.disposeVariables();
        }
    };
}

// Modified preprocessImageForRecognition function
function preprocessImageForRecognition(crops) {
    return tf.tidy(() => {
        const targetSize = [32, 128];
        const tensors = crops.map((crop) => {
            // Scale down if crop exceeds texture limits
            const scale = Math.min(
                MAX_TEXTURE_SIZE / crop.width,
                MAX_TEXTURE_SIZE / crop.height,
                1
            );
            
            const scaledWidth = Math.floor(crop.width * scale);
            const scaledHeight = Math.floor(crop.height * scale);
            
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = scaledWidth;
            tempCanvas.height = scaledHeight;
            const ctx = tempCanvas.getContext('2d');
            ctx.drawImage(crop, 0, 0, scaledWidth, scaledHeight);
            
            let h = scaledHeight;
            let w = scaledWidth;
            let resizeTarget, paddingTarget;
            let aspectRatio = targetSize[1] / targetSize[0];
            
            if (aspectRatio * h > w) {
                resizeTarget = [targetSize[0], Math.round((targetSize[0] * w) / h)];
                paddingTarget = [
                    [0, 0],
                    [0, targetSize[1] - Math.round((targetSize[0] * w) / h)],
                    [0, 0],
                ];
            } else {
                resizeTarget = [Math.round((targetSize[1] * h) / w), targetSize[1]];
                paddingTarget = [
                    [0, targetSize[0] - Math.round((targetSize[1] * h) / w)],
                    [0, 0],
                    [0, 0],
                ];
            }
            
            return tf.browser
                .fromPixels(tempCanvas)
                .resizeNearestNeighbor(resizeTarget)
                .pad(paddingTarget, 0)
                .toFloat()
                .expandDims();
        });
        
        const tensor = tf.concat(tensors);
        const mean = tf.scalar(255 * REC_MEAN);
        const std = tf.scalar(255 * REC_STD);
        return tensor.sub(mean).div(std);
    });
}
