importScripts('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest');

const VOCAB = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~°£€¥¢฿àâéèêëîïôùûüçÀÂÉÈÊËÎÏÔÙÛÜÇ";
const TARGET_SIZE = [512, 512];
const REC_MEAN = 0.694;
const REC_STD = 0.298;

onmessage = async function(event) {
    const { crops, detectionModel, recognitionModel } = event.data;

    const batchSize = 8; // Adjust batch size based on performance
    const numBatches = Math.ceil(crops.length / batchSize);
    const results = [];

    for (let i = 0; i < numBatches; i++) {
        const batch = crops.slice(i * batchSize, (i + 1) * batchSize);
        const batchResults = await processBatch(batch, recognitionModel);
        results.push(...batchResults);
    }

    postMessage(results);
};

async function processBatch(batch, recognitionModel) {
    const inputTensor = preprocessImageForRecognition(batch.map(crop => crop.canvas));
    const predictions = await recognitionModel.executeAsync(inputTensor);
    const probabilities = tf.softmax(predictions, -1);
    const bestPath = tf.unstack(tf.argMax(probabilities, -1), 0);
    const words = decodeText(bestPath);

    const result = words.split(' ').map((word, index) => ({
        word: word,
        boundingBox: batch[index].bbox
    }));

    tf.dispose([inputTensor, predictions, probabilities, ...bestPath]);
    return result;
}

function preprocessImageForRecognition(crops) {
    const targetSize = [32, 128];
    const tensors = crops.map((crop) => {
        let h = crop.height;
        let w = crop.width;
        let resizeTarget, paddingTarget;
        let aspectRatio = targetSize[1] / targetSize[0];
        if (aspectRatio * h > w) {
            resizeTarget = [targetSize[0], Math.round((targetSize[0] * w) / h)];
            paddingTarget = [
                [0, 0],
                [0, targetSize[1] - Math.round((targetSize[0] * w) / h)],
                [0, 0],
            ];
        } else {
            resizeTarget = [Math.round((targetSize[1] * h) / w), targetSize[1]];
            paddingTarget = [
                [0, targetSize[0] - Math.round((targetSize[1] * h) / w)],
                [0, 0],
                [0, 0],
            ];
        }
        return tf.tidy(() => {
            return tf.browser
                .fromPixels(crop)
                .resizeNearestNeighbor(resizeTarget)
                .pad(paddingTarget, 0)
                .toFloat()
                .expandDims();
        });
    });
    const tensor = tf.concat(tensors);
    let mean = tf.scalar(255 * REC_MEAN);
    let std = tf.scalar(255 * REC_STD);
    return tensor.sub(mean).div(std);
}

function decodeText(bestPath) {
    const blank = 126;
    let collapsed = "";
    let lastChar = null;

    for (const sequence of bestPath) {
        const values = sequence.dataSync();
        for (const k of values) {
            if (k !== blank && k !== lastChar) {         
                collapsed += VOCAB[k];
                lastChar = k;
            } else if (k === blank) {
                lastChar = null;
            }
        }
        collapsed += ' ';
    }
    return collapsed.trim();
}
