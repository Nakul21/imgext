async function detectAndRecognizeText(imageElement) {
    const results = [];
    let currentOperation = 'detection';
    
    try {
        // Update loading message
        updateLoadingMessage(currentOperation);
        
        // Detection phase - moved out of tf.tidy
        const tensor = preprocessImageForDetection(imageElement);
        const prediction = await detectionModel.execute(tensor);
        const squeezedPrediction = tf.squeeze(prediction, 0);
        
        // Create canvas and draw heatmap
        const heatmapCanvas = document.createElement('canvas');
        heatmapCanvas.width = TARGET_SIZE[0];
        heatmapCanvas.height = TARGET_SIZE[1];
        await tf.browser.toPixels(squeezedPrediction, canvas);
        
        // Clean up tensors
        tensor.dispose();
        prediction.dispose();
        squeezedPrediction.dispose();

        currentOperation = 'processing';
        updateLoadingMessage(currentOperation);

        const boundingBoxes = extractBoundingBoxesFromHeatmap(heatmapCanvas, TARGET_SIZE);
        
        // Efficient canvas drawing
        const ctx = previewCanvas.getContext('2d', { alpha: false });
        ctx.drawImage(imageElement, 0, 0, TARGET_SIZE[0], TARGET_SIZE[1]);
        
        // Optimized crop creation
        const crops = await createCropsEfficiently(boundingBoxes, imageElement);
        
        currentOperation = 'recognition';
        updateLoadingMessage(currentOperation);

        // Process crops in optimized batches
        const batchSize = isMobile() ? 4 : 16; // Smaller batches for mobile
        for (let i = 0; i < crops.length; i += batchSize) {
            const batch = crops.slice(i, i + batchSize);
            
            // Update progress
            updateProgress(i, crops.length);
            
            // Move tensor operations outside of tidy
            const inputTensor = preprocessImageForRecognition(batch.map(crop => crop.canvas));
            const predictions = await recognitionModel.executeAsync(inputTensor);
            const probabilities = tf.softmax(predictions, -1);
            const bestPath = tf.argMax(probabilities, -1).arraySync();
            
            const words = decodeText(bestPath.map(path => tf.tensor1d(path)));
            words.split(' ').forEach((word, index) => {
                if (word && batch[index]) {
                    results.push({
                        word: word,
                        boundingBox: batch[index].bbox
                    });
                }
            });
            
            // Clean up tensors
            inputTensor.dispose();
            predictions.dispose();
            probabilities.dispose();
            
            // Force garbage collection after each batch if available
            if (window.gc) window.gc();
            
            // Allow UI thread to breathe between batches
            await new Promise(resolve => setTimeout(resolve, 0));
        }
        
        return results;
    } finally {
        tf.disposeVariables();
    }
}
