
async function detectAndRecognizeText(imageElement) {
    
    if (isMobile()) {
        useCPU(); // Switch to CPU for mobile devices
    }
    const heatmapCanvas = await getHeatMapFromImage(imageElement);
    const boundingBoxes = extractBoundingBoxesFromHeatmap(heatmapCanvas, TARGET_SIZE);

    previewCanvas.width = TARGET_SIZE[0];
    previewCanvas.height = TARGET_SIZE[1];
    const ctx = previewCanvas.getContext('2d');
    ctx.drawImage(imageElement, 0, 0);

    let extractedData = [];
    const crops = [];

    try {
        for (const box of boundingBoxes) {
            // Draw bounding box
            const [x1, y1] = box.coordinates[0];
            const [x2, y2] = box.coordinates[2];
            const width = (x2 - x1) * imageElement.width;
            const height = (y2 - y1) * imageElement.height;
            const x = x1 * imageElement.width;
            const y = y1 * imageElement.height;

            ctx.strokeStyle = box.config.stroke;
            ctx.lineWidth = 2;
            ctx.strokeRect(x, y, width, height);

            // Create crop
            const croppedCanvas = document.createElement('canvas');
            croppedCanvas.width = Math.min(width, 128);
            croppedCanvas.height = Math.min(height, 32);
            croppedCanvas.getContext('2d').drawImage(
                imageElement, 
                x, y, width, height,
                0, 0, width, height
            );

            crops.push({ canvas: croppedCanvas, bbox: { x, y, width, height } });
        }

        // Process crops in batches
        const batchSize = isMobile() ? 32 : 32;
        for (let i = 0; i < crops.length; i += batchSize) {
            const batch = crops.slice(i, i + batchSize);
            const inputTensor = preprocessImageForRecognition(batch.map(crop => crop.canvas));

            const predictions = await recognitionModel.executeAsync(inputTensor);
            const probabilities = tf.softmax(predictions, -1);
            const bestPath = tf.unstack(tf.argMax(probabilities, -1), 0);
            
            const words = decodeText(bestPath);
            
            // Associate each word with its bounding box
            words.split(' ').forEach((word, index) => {
                if (word) {
                    extractedData.push({
                        word: word,
                        boundingBox: batch[index].bbox
                    });
                }
            });

            tf.dispose([inputTensor, predictions, probabilities, ...bestPath]);
        }
        
        return extractedData;
        
    } catch(error) {
        console.error('Error in detectAndRecognizeText:', error);
        throw error;
    } finally {
        tf.disposeVariables(); // Clean up any remaining tensors
    }
}

async function handleCapture() {
    disableCaptureButton();
    showLoading('Processing image...');

    await ensureModelsLoaded();  // Ensure models are loaded before processing

    const targetSize = TARGET_SIZE;
    canvas.width = targetSize[0];
    canvas.height = targetSize[1];
    canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);

    imageDataUrl = canvas.toDataURL('image/jpeg', isMobile() ? 0.7 : 0.9);
    
    const img = new Image();
    img.src = imageDataUrl;
    img.onload = async () => {
        try {
            extractedData = await detectAndRecognizeText(img);
            const extractedText = extractedData.map(item => item.word).join(' ');
            resultElement.textContent = `Extracted Text: ${extractedText}`;
            
            previewCanvas.style.display = 'block';
            confirmButton.style.display = 'inline-block';
            retryButton.style.display = 'inline-block';
            captureButton.style.display = 'none';
        } catch (error) {
            console.error('Error during text extraction:', error);
            resultElement.textContent = 'Error occurred during text extraction';
        } finally {
            enableCaptureButton();
            hideLoading();
            tf.disposeVariables();
        }
    };
}

async function handleSend() {
    if (!extractedData) return;
    apiResponseElement.textContent = 'Submitting...';
    let msgKey = new Date().getTime();
    try {
        const response = await fetch('https://kvdb.io/NyKpFtJ7v392NS8ibLiofx/'+msgKey, {
            method: 'PUT',
            body: JSON.stringify({
                extractedAt: msgKey,
                data: extractedData,
                userId: "imageExt",
            }),
            headers: {
                'Content-type': 'application/json; charset=UTF-8',
            },
        });

        if (response.status !== 200) {
            throw new Error('Failed to push this data to server');
        } 
        
        apiResponseElement.textContent = 'Submitted the extract with ID : ' + msgKey; 
        
    } catch (error) {
        console.error('Error submitting to server:', error);
        apiResponseElement.textContent = 'Error occurred while submitting to server';
    } finally {
        resetUI();
    }
}

