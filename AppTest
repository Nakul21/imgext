// Add new constants for image processing
const MOBILE_MAX_DIMENSION = 1024; // Maximum texture dimension for mobile
const DESKTOP_MAX_DIMENSION = 2048; // Maximum texture dimension for desktop
const MOBILE_BATCH_SIZE = 4; // Smaller batch size for mobile
const DESKTOP_BATCH_SIZE = 32; // Regular batch size for desktop

// Add function to check device capabilities
function getDeviceCapabilities() {
    const canvas = document.createElement('canvas');
    const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
    
    if (!gl) {
        return {
            maxTextureSize: MOBILE_MAX_DIMENSION,
            isMobile: true
        };
    }

    const maxTextureSize = gl.getParameter(gl.MAX_TEXTURE_SIZE);
    const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
    
    return {
        maxTextureSize: Math.min(maxTextureSize, isMobile ? MOBILE_MAX_DIMENSION : DESKTOP_MAX_DIMENSION),
        isMobile
    };
}

// Function to resize image while maintaining aspect ratio
function calculateResizeDimensions(width, height, maxDimension) {
    if (width <= maxDimension && height <= maxDimension) {
        return { width, height };
    }
    
    const aspectRatio = width / height;
    
    if (width > height) {
        return {
            width: maxDimension,
            height: Math.round(maxDimension / aspectRatio)
        };
    } else {
        return {
            width: Math.round(maxDimension * aspectRatio),
            height: maxDimension
        };
    }
}

// Modified preprocessImageForDetection with size constraints
function preprocessImageForDetection(imageElement) {
    const deviceCaps = getDeviceCapabilities();
    
    return tf.tidy(() => {
        // First resize the image to device-appropriate dimensions
        const { width, height } = calculateResizeDimensions(
            imageElement.width,
            imageElement.height,
            deviceCaps.maxTextureSize
        );
        
        // Create a temporary canvas for resizing
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = width;
        tempCanvas.height = height;
        const ctx = tempCanvas.getContext('2d');
        ctx.drawImage(imageElement, 0, 0, width, height);
        
        // Convert to tensor with controlled dimensions
        const tensor = tf.browser
            .fromPixels(tempCanvas)
            .resizeNearestNeighbor(TARGET_SIZE)
            .toFloat();
            
        const mean = tf.scalar(255 * DET_MEAN);
        const std = tf.scalar(255 * DET_STD);
        return tensor.sub(mean).div(std).expandDims();
    });
}

// Modified preprocessImageForRecognition with size constraints
function preprocessImageForRecognition(crops) {
    const deviceCaps = getDeviceCapabilities();
    
    return tf.tidy(() => {
        const targetSize = [32, 128];
        const tensors = crops.map((crop) => {
            // Resize crop if it exceeds device limits
            const { width: resizedWidth, height: resizedHeight } = calculateResizeDimensions(
                crop.width,
                crop.height,
                deviceCaps.maxTextureSize / 2 // Use half of max texture size for safety
            );
            
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = resizedWidth;
            tempCanvas.height = resizedHeight;
            const ctx = tempCanvas.getContext('2d');
            ctx.drawImage(crop, 0, 0, resizedWidth, resizedHeight);
            
            let h = resizedHeight;
            let w = resizedWidth;
            let resizeTarget, paddingTarget;
            let aspectRatio = targetSize[1] / targetSize[0];
            
            if (aspectRatio * h > w) {
                resizeTarget = [targetSize[0], Math.round((targetSize[0] * w) / h)];
                paddingTarget = [
                    [0, 0],
                    [0, targetSize[1] - Math.round((targetSize[0] * w) / h)],
                    [0, 0],
                ];
            } else {
                resizeTarget = [Math.round((targetSize[1] * h) / w), targetSize[1]];
                paddingTarget = [
                    [0, targetSize[0] - Math.round((targetSize[1] * h) / w)],
                    [0, 0],
                    [0, 0],
                ];
            }
            
            return tf.browser
                .fromPixels(tempCanvas)
                .resizeNearestNeighbor(resizeTarget)
                .pad(paddingTarget, 0)
                .toFloat()
                .expandDims();
        });
        
        const tensor = tf.concat(tensors);
        const mean = tf.scalar(255 * REC_MEAN);
        const std = tf.scalar(255 * REC_STD);
        return tensor.sub(mean).div(std);
    });
}

// Modified processBatch function with dynamic batch sizing
async function processBatch(batch, extractedData) {
    const deviceCaps = getDeviceCapabilities();
    const batchSize = deviceCaps.isMobile ? MOBILE_BATCH_SIZE : DESKTOP_BATCH_SIZE;
    
    // Process in smaller sub-batches if needed
    for (let i = 0; i < batch.length; i += batchSize) {
        const subBatch = batch.slice(i, i + batchSize);
        let inputTensor = null;
        let predictions = null;
        let probabilities = null;
        let bestPath = null;
        
        try {
            inputTensor = preprocessImageForRecognition(subBatch.map(crop => crop.canvas));
            predictions = await recognitionModel.executeAsync(inputTensor);
            probabilities = tf.softmax(predictions, -1);
            bestPath = tf.unstack(tf.argMax(probabilities, -1), 0);
            
            const words = decodeText(bestPath);
            
            words.split(' ').forEach((word, index) => {
                if (word && subBatch[index]) {
                    extractedData.push({
                        word: word,
                        boundingBox: subBatch[index].bbox
                    });
                }
            });
            
            // Force garbage collection after each sub-batch
            await tf.nextFrame();
            
        } finally {
            // Clean up tensors
            if (inputTensor) inputTensor.dispose();
            if (predictions) predictions.dispose();
            if (probabilities) probabilities.dispose();
            if (bestPath) bestPath.forEach(t => t.dispose());
        }
    }
}

// Modified detectAndRecognizeText with additional optimizations
async function detectAndRecognizeText(imageElement) {
    const deviceCaps = getDeviceCapabilities();
    
    if (deviceCaps.isMobile) {
        useCPU();
    }
    
    let heatmapCanvas = null;
    
    try {
        // Resize input image if needed
        const { width, height } = calculateResizeDimensions(
            imageElement.width,
            imageElement.height,
            deviceCaps.maxTextureSize
        );
        
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = width;
        tempCanvas.height = height;
        const ctx = tempCanvas.getContext('2d');
        ctx.drawImage(imageElement, 0, 0, width, height);
        
        // Process resized image
        heatmapCanvas = await getHeatMapFromImage(tempCanvas);
        const boundingBoxes = extractBoundingBoxesFromHeatmap(heatmapCanvas, TARGET_SIZE);
        
        // Setup preview canvas
        previewCanvas.width = width;
        previewCanvas.height = height;
        previewCanvas.getContext('2d').drawImage(tempCanvas, 0, 0);
        
        // Rest of the processing...
        // [Previous crop generation code remains the same]
        
        // Process in smaller batches for mobile
        const batchSize = deviceCaps.isMobile ? MOBILE_BATCH_SIZE : DESKTOP_BATCH_SIZE;
        
        for (let i = 0; i < crops.length; i += batchSize) {
            const batch = crops.slice(i, i + batchSize);
            await processBatch(batch, extractedData);
            
            // Force garbage collection between batches
            if (deviceCaps.isMobile) {
                await new Promise(resolve => setTimeout(resolve, 100)); // Add small delay on mobile
            }
            await tf.nextFrame();
        }
        
        return extractedData;
        
    } catch(error) {
        console.error('Error in detectAndRecognizeText:', error);
        throw error;
    } finally {
        // Clean up any remaining tensors
        tf.engine().startScope();
        tf.engine().endScope();
        await tf.nextFrame();
    }
}
