// Constants
const REC_MEAN = 0.694;
const REC_STD = 0.298;
const DET_MEAN = 0.785;
const DET_STD = 0.275;
const VOCAB = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~°£€¥¢฿àâéèêëîïôùûüçÀÂÉÈÊËÎÏÔÙÛÜÇ";

// DOM Elements
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const previewCanvas = document.getElementById('previewCanvas');
const captureButton = document.getElementById('captureButton');
const confirmButton = document.getElementById('confirmButton');
const retryButton = document.getElementById('retryButton');
const actionButtons = document.getElementById('actionButtons');
const sendButton = document.getElementById('sendButton');
const discardButton = document.getElementById('discardButton');
const resultElement = document.getElementById('result');
const apiResponseElement = document.getElementById('apiResponse');
const loadingIndicator = document.getElementById('loadingIndicator');

let imageDataUrl = '';
let extractedText = '';
let detectionModel;
let recognitionModel;
let boundingBoxes = [];

// ... (previous functions remain the same)

function decodeText(bestPath) {
    const blank = 126;
    let collapsed = "";
    let lastChar = null;

    for (const sequence of bestPath) {
        const values = sequence.dataSync();
        for (const k of values) {
            if (k !== blank && k !== lastChar) {
                if (collapsed.length > 0 && !VOCAB[k].match(/[.,!?;:]/)) {
                    collapsed += ' '; // Add space before new word
                }
                collapsed += VOCAB[k];
                lastChar = k;
            } else if (k === blank) {
                lastChar = null;
            }
        }
    }
    return collapsed.trim();
}

async function detectAndRecognizeText(imageElement) {
    const size = [512, 512];
    const heatmapCanvas = await getHeatMapFromImage(imageElement);
    boundingBoxes = extractBoundingBoxesFromHeatmap(heatmapCanvas, size);
    console.log('extractBoundingBoxesFromHeatmap', boundingBoxes);

    previewCanvas.width = imageElement.width;
    previewCanvas.height = imageElement.height;
    const ctx = previewCanvas.getContext('2d');
    ctx.drawImage(imageElement, 0, 0);

    let fullText = '';
    const crops = [];
    const extractedWords = [];

    // Limit the number of bounding boxes processed on mobile
    const maxBoxes = isMobile() ? 10 : boundingBoxes.length;
    for (let i = 0; i < Math.min(maxBoxes, boundingBoxes.length); i++) {
        const box = boundingBoxes[i];
        // Draw bounding box
        const [x1, y1] = box.coordinates[0];
        const [x2, y2] = box.coordinates[2];
        const width = (x2 - x1) * imageElement.width;
        const height = (y2 - y1) * imageElement.height;
        const x = x1 * imageElement.width;
        const y = y1 * imageElement.height;

        ctx.strokeStyle = box.config.stroke;
        ctx.lineWidth = 2;
        ctx.strokeRect(x, y, width, height);

        // Create crop
        const croppedCanvas = document.createElement('canvas');
        croppedCanvas.width = width;
        croppedCanvas.height = height;
        croppedCanvas.getContext('2d').drawImage(
            imageElement, 
            x, y, width, height,
            0, 0, width, height
        );

        crops.push(croppedCanvas);
    }

    // Process crops in smaller batches on mobile
    const batchSize = isMobile() ? 4 : 32;
    for (let i = 0; i < crops.length; i += batchSize) {
        const batch = crops.slice(i, i + batchSize);
        const inputTensor = preprocessImageForRecognition(batch);

        // Use lower precision on mobile
        const predictions = await recognitionModel.executeAsync(inputTensor, {
            precision: isMobile() ? 'low' : 'high'
        });
        const probabilities = tf.softmax(predictions, -1);
        const bestPath = tf.unstack(tf.argMax(probabilities, -1), 0);
        
        const words = decodeText(bestPath);
        fullText += words + ' ';

        // Store extracted words for each bounding box
        for (let j = 0; j < batch.length; j++) {
            extractedWords.push({
                boundingBox: boundingBoxes[i + j],
                text: words
            });
        }

        tf.dispose([inputTensor, predictions, probabilities, ...bestPath]);
    }
    
    return { fullText: fullText.trim(), extractedWords };
}

function isMobile() {
    return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
}

async function handleCapture() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);
    
    imageDataUrl = canvas.toDataURL('image/jpeg', isMobile() ? 0.7 : 0.9);
    resultElement.textContent = 'Processing image...';
    
    const img = new Image();
    img.src = imageDataUrl;
    img.onload = async () => {
        try {
            loadingIndicator.style.display = 'block';
            const { fullText, extractedWords } = await detectAndRecognizeText(img);
            extractedText = fullText;
            resultElement.textContent = `Extracted Text: ${extractedText}`;
            
            // Store extracted words for later use
            window.extractedWords = extractedWords;
            
            // Show preview canvas and confirmation buttons
            previewCanvas.style.display = 'block';
            confirmButton.style.display = 'inline-block';
            retryButton.style.display = 'inline-block';
            captureButton.style.display = 'none';
        } catch (error) {
            console.error('Error during text extraction:', error);
            resultElement.textContent = 'Error occurred during text extraction';
        } finally {
            loadingIndicator.style.display = 'none';
        }
    };
}

async function handleSend() {
    if (!extractedText) return;
    apiResponseElement.textContent = 'Submitting...';
    let msgKey = new Date().getTime();
    try {
        const response = await fetch('https://kvdb.io/NyKpFtJ7v392NS8ibLiofx/'+msgKey, {
            method: 'PUT',
            body: JSON.stringify({
                extractedAt: msgKey,
                data: extractedText,
                userId: "imageExt",
                boundingBoxes: boundingBoxes,
                extractedWords: window.extractedWords
            }),
            headers: {
                'Content-type': 'application/json; charset=UTF-8',
            },
        });

        if (response.status !== 200) {
            throw new Error('Failed to push this data to server');
        } 
        
        apiResponseElement.textContent = 'Submitted the extract with ID : ' + msgKey; 
        
    } catch (error) {
        console.error('Error submitting to server:', error);
        apiResponseElement.textContent = 'Error occurred while submitting to server';
    } finally {
        resetUI();
    }
}

async function init() {
    loadingIndicator.style.display = 'block';
    await Promise.all([
        loadModels(),
        loadOpenCV(),
        setupCamera()
    ]);
    captureButton.disabled = false;
    captureButton.textContent = 'Capture';
    loadingIndicator.style.display = 'none';
}

// ... (rest of the code remains the same)
